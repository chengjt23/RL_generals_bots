_wandb:
    value:
        cli_version: 0.23.0
        e:
            vk54evqwv8viiw5uly0ishm22k7r02cr:
                args:
                    - --config
                    - configs/config_sac.yaml
                codePath: train_sac.py
                codePathLocal: train_sac.py
                email: chengyon23@mails.tsinghua.edu.cn
                executable: /root/miniconda3/envs/rl/bin/python
                git:
                    commit: fa2a4fbf259d528b34797da2ed70661b5b24fe38
                    remote: https://github.com/chengjt23/RL_generals_bots.git
                host: p-acf455511d83-ackcs-00gjftw7
                os: Linux-5.15.0-119-generic-x86_64-with-glibc2.39
                program: /root/RL_generals_bots/train_sac.py
                python: CPython 3.11.14
                root: /root/RL_generals_bots
                startedAt: "2025-12-11T16:01:03.261344Z"
                writerId: vk54evqwv8viiw5uly0ishm22k7r02cr
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.11.14
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
environment:
    value:
        max_episode_steps: 500
        num_parallel_envs: 1
experiment:
    value:
        bc_pretrain_path: ./experiments/epoch_12_loss_1.6968.pt
        name: sac_from_bc
        save_dir: experiments
logging:
    value:
        project_name: generals-rl
        use_wandb: true
        wandb_entity: null
model:
    value:
        base_channels: 64
        grid_size: 24
        memory_channels: 18
        obs_channels: 15
reward:
    value:
        army_weight: 0.3
        castle_weight: 0.4
        gamma: 0.99
        land_weight: 0.3
        max_ratio: 100
        type: potential_based
training:
    value:
        actor_lr: 0.0003
        alpha: 0.2
        alpha_lr: 0.0003
        auto_tune_alpha: true
        batch_size: 128
        buffer_size: 100000
        critic_lr: 0.0003
        device: cuda
        eval_frequency: 10000
        gamma: 0.99
        gradient_steps: 1
        learning_starts: 10000
        log_frequency: 1000
        save_frequency: 50000
        seed: 42
        tau: 0.005
        total_timesteps: 1000000
        update_frequency: 1

[34m[1mwandb[0m: Detected [agents] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/

============================================================
Offline SAC Training
============================================================
Training mode: Offline (using replay data)
Data source: data/generals_io_replays
BC pretrain: ./experiments/epoch_12_loss_1.6968.pt
Total epochs: 10
Batch size: 128
============================================================
Epoch 1/10: 0it [00:01, ?it/s]
Traceback (most recent call last):
  File "/root/RL_generals_bots/train_offline_sac.py", line 204, in <module>
    main()
  File "/root/RL_generals_bots/train_offline_sac.py", line 200, in main
    trainer.train()
  File "/root/RL_generals_bots/train_offline_sac.py", line 127, in train
    metrics = self.agent.update(batch)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/RL_generals_bots/agents/sac_agent.py", line 213, in update
    critic_loss.backward()
  File "/root/miniconda3/envs/rl/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/root/miniconda3/envs/rl/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/root/miniconda3/envs/rl/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Found dtype Double but expected Float

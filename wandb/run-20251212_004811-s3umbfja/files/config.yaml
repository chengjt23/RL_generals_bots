_wandb:
    value:
        cli_version: 0.23.0
        e:
            ttr1pdfocu9jgg6gcvkg2lfwdd73nily:
                args:
                    - --config
                    - configs/config_sac.yaml
                codePath: train_sac.py
                codePathLocal: train_sac.py
                cpu_count: 64
                cpu_count_logical: 128
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "32212254720"
                        used: "23081406464"
                email: chengyon23@mails.tsinghua.edu.cn
                executable: /root/miniconda3/envs/rl/bin/python
                git:
                    commit: 5c1ed09488f05ba7bb44a7d73dbba0b7bf4f3cc5
                    remote: https://github.com/chengjt23/RL_generals_bots.git
                gpu: NVIDIA GeForce RTX 4090
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ada
                      cudaCores: 16384
                      memoryTotal: "25757220864"
                      name: NVIDIA GeForce RTX 4090
                      uuid: GPU-63c94b1b-0227-3332-779c-90bc491f56aa
                host: p-acf455511d83-ackcs-00gjftw7
                memory:
                    total: "1081819086848"
                os: Linux-5.15.0-119-generic-x86_64-with-glibc2.39
                program: /root/RL_generals_bots/train_sac.py
                python: CPython 3.11.14
                root: /root/RL_generals_bots
                startedAt: "2025-12-11T16:48:11.477197Z"
                writerId: ttr1pdfocu9jgg6gcvkg2lfwdd73nily
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
                - 61
            "4": 3.11.14
            "5": 0.23.0
            "12": 0.23.0
            "13": linux-x86_64
environment:
    value:
        max_episode_steps: 500
        num_parallel_envs: 1
experiment:
    value:
        bc_pretrain_path: ./experiments/epoch_12_loss_1.6968.pt
        name: sac_from_bc
        save_dir: experiments
logging:
    value:
        project_name: generals-rl
        use_wandb: true
        wandb_entity: null
model:
    value:
        base_channels: 64
        grid_size: 24
        memory_channels: 18
        obs_channels: 15
reward:
    value:
        army_weight: 0.3
        castle_weight: 0.4
        gamma: 0.99
        land_weight: 0.3
        max_ratio: 100
        type: potential_based
training:
    value:
        actor_lr: 0.0003
        alpha: 0.2
        alpha_lr: 0.0003
        auto_tune_alpha: true
        batch_size: 128
        buffer_size: 100000
        critic_lr: 0.0003
        device: cuda
        eval_frequency: 10000
        gamma: 0.99
        gradient_steps: 1
        learning_starts: 10000
        log_frequency: 1000
        pool_update_frequency: 10000
        random_prob_after_selfplay: 0.2
        save_frequency: 50000
        seed: 42
        self_play_start: 100000
        tau: 0.005
        total_timesteps: 1000000
        update_frequency: 1

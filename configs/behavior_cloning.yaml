training:
  batch_size: 8
  learning_rate: 0.0003
  num_epochs: 5
  gradient_clip: 1.0
  warmup_steps: 100
  weight_decay: 0.0001
  
  save_top_k: 3
  eval_every: 1000
  log_every: 50
  
  device: cpu
  num_workers: 0
  mixed_precision: false

data:
  data_dir: data/generals_io_replays
  grid_size: 24
  min_stars: 70
  max_turns: 500
  max_replays: 1000
  train_split: 0.95

model:
  obs_channels: 15
  memory_channels: 0
  base_channels: 64
  grid_size: 24

optimizer:
  type: adamw
  betas: [0.9, 0.999]
  eps: 1.0e-8

scheduler:
  type: cosine
  warmup_epochs: 5
  min_lr: 1.0e-6

logging:
  experiment_name: behavior_cloning
  save_dir: RL/experiments
  tensorboard: true

seed: 42


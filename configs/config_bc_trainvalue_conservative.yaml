# Conservative config - 更稳定的训练参数，适合初次尝试
training:
  batch_size: 512          # 较小batch，更稳定
  learning_rate: 0.0001    # 较小学习率
  num_epochs: 100
  steps_per_epoch: 1000
  gradient_clip: 1.0
  warmup_steps: 2000       # 更长warm up
  weight_decay: 0.0001
  
  # N-step TD parameters (conservative settings)
  n_step: 30               # 较小的n，减少方差
  gamma: 0.99              # 标准折扣因子
  tau: 0.003               # 更慢的target network更新
  value_weight: 0.3        # 更小的value权重，优先policy
  
  save_top_k: 5
  eval_every: 1000
  log_every: 100
  
  device: cuda
  num_workers: 4
  mixed_precision: true

  early_stopping:
    enabled: true
    patience: 15           # 更长的patience
    min_delta: 0.001

data:
  data_dir: data/generals_io_replays
  grid_size: 24
  min_stars: 70
  max_turns: 500
  max_replays: 18803
  train_split: 0.95

model:
  obs_channels: 15
  memory_channels: 20
  base_channels: 64
  grid_size: 24

optimizer:
  type: adamw
  betas: [0.9, 0.95]
  eps: 1.0e-8

scheduler:
  type: cosine
  warmup_epochs: 5
  min_lr: 1.0e-6

logging:
  experiment_name: bc_trainvalue_conservative
  save_dir: experiments
  tensorboard: true
  use_wandb: true
  wandb_project: generals-rl
  wandb_tags: [behavior_cloning, value_head, nstep_td, conservative]

seed: 42


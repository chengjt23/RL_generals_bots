# Generals.io RL Training Pipeline

## ğŸ“– æ–‡æ¡£å¯¼èˆª

- **[æ¨¡å‹æ¶æ„è¯¦ç»†è¯´æ˜](MODEL_ARCHITECTURE.md)** - å®Œæ•´çš„æ¨¡å‹æ¶æ„ã€è¾“å…¥è¾“å‡ºè§„æ ¼å’Œæ•°æ®æµè¯´æ˜ï¼ˆä¾¿äºç»˜å›¾ï¼‰
- æœ¬æ–‡æ¡£ - è®­ç»ƒæµç¨‹å’Œä½¿ç”¨æŒ‡å—

## ç›®å½•ç»“æ„

```
RL_generals_bots/
â”œâ”€â”€ agents/               # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory.py        # è®°å¿†å¢å¼º
â”‚   â”œâ”€â”€ network.py       # U-Net + Policy/Value å¤´
â”‚   â”œâ”€â”€ reward_shaping.py # åŠ¿å‡½æ•°å¥–åŠ±æ•´å½¢
â”‚   â””â”€â”€ sota_agent.py    # SOTA æ™ºèƒ½ä½“
â”œâ”€â”€ configs/             # è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ behavior_cloning.yaml
â”œâ”€â”€ data/                # æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ dataloader.py    # æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ download.py      # ä¸‹è½½è„šæœ¬
â”‚   â””â”€â”€ generals_io_replays/  # æ•°æ®é›†ç›®å½•
â”œâ”€â”€ experiments/         # å®éªŒè¾“å‡ºï¼ˆcheckpoints, logsï¼‰
â””â”€â”€ train_bc.py         # è¡Œä¸ºå…‹éš†è®­ç»ƒè„šæœ¬
```

## ç¯å¢ƒå‡†å¤‡

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### ä¸‹è½½æ•°æ®é›†
```bash
cd RL_generals_bots
cd data
python download.py
```

## è®­ç»ƒæµç¨‹

### ç¬¬ä¸€æ­¥ï¼šè¡Œä¸ºå…‹éš†ï¼ˆBehavior Cloningï¼‰

æŒ‰ç…§è®ºæ–‡æè¿°ï¼Œä½¿ç”¨é«˜è´¨é‡å¯¹å±€è¿›è¡Œè¡Œä¸ºå…‹éš†é¢„è®­ç»ƒã€‚

#### é…ç½®è¯´æ˜ (`configs/config_base.yaml`)

```yaml
training:
  batch_size: 64          # æ‰¹é‡å¤§å°
  learning_rate: 0.0003   # å­¦ä¹ ç‡
  num_epochs: 100         # è®­ç»ƒè½®æ•°
  gradient_clip: 1.0      # æ¢¯åº¦è£å‰ª
  warmup_steps: 1000      # é¢„çƒ­æ­¥æ•°
  save_top_k: 5          # ä¿å­˜æœ€å¥½çš„ 5 ä¸ªæ¨¡å‹

data:
  min_stars: 70          # æœ€ä½æ˜Ÿçº§è¦æ±‚ï¼ˆè®ºæ–‡è®¾å®šï¼‰
  max_turns: 500         # æœ€å¤§å›åˆæ•°ï¼ˆè®ºæ–‡è®¾å®šï¼‰
  grid_size: 24          # ç½‘æ ¼å¤§å°

model:
  obs_channels: 15       # è§‚æµ‹é€šé“æ•°
  memory_channels: 0     # BC é˜¶æ®µä¸ä½¿ç”¨è®°å¿†
  base_channels: 64      # åŸºç¡€é€šé“æ•°
```

#### å¯åŠ¨è®­ç»ƒ
```bash
cd RL_generals_bots
python train_bc.py --config configs/config_base.yaml
```

#### è®­ç»ƒè¾“å‡º
è®­ç»ƒè¿‡ç¨‹ä¼šåœ¨ `experiments/` ä¸‹åˆ›å»ºå®éªŒç›®å½•ï¼š
```
experiments/
â””â”€â”€ behavior_cloning_20250128_143022/
    â”œâ”€â”€ config.yaml           # ä¿å­˜çš„é…ç½®
    â”œâ”€â”€ metrics.json          # è®­ç»ƒæŒ‡æ ‡
    â””â”€â”€ checkpoints/          # æ¨¡å‹æ£€æŸ¥ç‚¹
        â”œâ”€â”€ epoch_10_loss_0.1234.pt
        â”œâ”€â”€ epoch_20_loss_0.0987.pt
        â””â”€â”€ ...ï¼ˆæœ€å¤šä¿å­˜ top 5ï¼‰
```

#### ç›‘æ§è®­ç»ƒ
- ä½¿ç”¨ tqdm è¿›åº¦æ¡å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
- `metrics.json` è®°å½•æ¯ä¸ª epoch çš„æŸå¤±å’Œå­¦ä¹ ç‡
- æ¯ä¸ª epoch åè‡ªåŠ¨éªŒè¯å¹¶ä¿å­˜æœ€ä½³æ¨¡å‹

## æ•°æ®é›†å¤„ç†

### æ•°æ®è¿‡æ»¤æ ‡å‡†ï¼ˆä¸¥æ ¼æŒ‰è®ºæ–‡ï¼‰
1. âœ… æ¸¸æˆå›åˆæ•° â‰¤ 500
2. âœ… è‡³å°‘ä¸€åç©å®¶æ˜Ÿçº§ â‰¥ 70
3. âœ… æœ€æ–°æ¸¸æˆç‰ˆæœ¬

### æ•°æ®æå–
- ä» replay é‡å»ºå®Œæ•´æ¸¸æˆçŠ¶æ€
- ä¸ºæ¯ä¸ªåŠ¨ä½œæå– (observation, action, player_index) ä¸‰å…ƒç»„
- è‡ªåŠ¨å¤„ç†åŠ¨ä½œè½¬æ¢ï¼ˆtile index â†’ row/col/directionï¼‰

### åŠ¨ä½œç¼–ç 
- Pass: [1, 0, 0, 0, 0]
- Move: [0, row, col, direction, split]
  - direction: 0=ä¸Š, 1=ä¸‹, 2=å·¦, 3=å³
  - split: 0=å…¨éƒ¨, 1=ä¸€åŠ

## è®ºæ–‡å¤ç°å¯¹ç…§

| è®ºæ–‡æè¿° | å®ç°çŠ¶æ€ |
|---------|---------|
| 347,000 â†’ 16,320 é«˜è´¨é‡å¯¹å±€ | âœ… è¿‡æ»¤é€»è¾‘å·²å®ç° |
| æ˜Ÿçº§ â‰¥ 70 | âœ… `min_stars=70` |
| å›åˆ â‰¤ 500 | âœ… `max_turns=500` |
| 3 å°æ—¶ H100 è®­ç»ƒ | âœ… å¯é…ç½® `num_epochs` |
| è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒ | âœ… `train_bc.py` |
| U-Net æ¶æ„ | âœ… `network.py` |

## ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

```python
from agents import SOTAAgent

# åŠ è½½æ£€æŸ¥ç‚¹
agent = SOTAAgent(
    id="SOTA",
    grid_size=24,
    model_path="experiments/behavior_cloning_xxx/checkpoints/best_model.pt"
)

# åœ¨ç¯å¢ƒä¸­ä½¿ç”¨
from generals.envs import PettingZooGenerals
env = PettingZooGenerals(agents=["SOTA", "Random"])
obs, _ = env.reset()
action = agent.act(obs["SOTA"])
```

## ä¸‹ä¸€æ­¥ï¼šè‡ªåšå¼ˆè®­ç»ƒï¼ˆå¾…å®ç°ï¼‰

è¡Œä¸ºå…‹éš†å®Œæˆåï¼Œéœ€è¦å®ç°ï¼š
1. PPO è‡ªåšå¼ˆè®­ç»ƒå¾ªç¯
2. å¯¹æ‰‹æ± ç®¡ç†ï¼ˆä¿ç•™æœ€è¿‘ N=3 ä¸ªç‰ˆæœ¬ï¼‰
3. GAE (Î»=0.95) ä¼˜åŠ¿ä¼°è®¡
4. åŠ¿å‡½æ•°å¥–åŠ±æ•´å½¢

## æ•…éšœæ’é™¤

### å†…å­˜ä¸è¶³
- å‡å° `batch_size`
- å‡å° `base_channels`
- è®¾ç½® `max_replays` é™åˆ¶æ•°æ®é›†å¤§å°

### è®­ç»ƒé€Ÿåº¦æ…¢
- å¢åŠ  `num_workers`
- å¯ç”¨ `mixed_precision: true`
- ä½¿ç”¨æ›´å¼ºçš„ GPU

### æ•°æ®åŠ è½½é”™è¯¯
- ç¡®ä¿ä¸‹è½½å®Œæ•´æ•°æ®é›†
- æ£€æŸ¥ `data_dir` è·¯å¾„æ­£ç¡®
- å°è¯•æ›´æ–° pyarrow: `pip install -U pyarrow`

